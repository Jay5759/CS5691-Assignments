\documentclass[12pt, a4paper]{article}
\usepackage{amsmath}% For the equation* environment
\usepackage{graphicx}% LaTeX package to import graphics
\usepackage{tcolorbox}
\usepackage{ulem} % for underlining text
\usepackage{etoolbox} % for patching \section
\usepackage[table]{xcolor}
\usepackage[hidelinks]{hyperref}
\usepackage{tocloft} % LaTeX package to customize table of contents
\graphicspath{{Images/}} % configuring the graphicx package

% Define a new command for underlined section headings
\newcommand{\ulsection}[1]{\texorpdfstring{\uline{#1}}{#1}}

% Patch \section to use \ulsection
\makeatletter
\patchcmd{\@sect}{\@xsect}{\def\@xsect##1{\ulsection{##1}}\@xsect}{}{}
\makeatother

\title{\textbf{\huge CS5691 - Pattern Recognition in Machine Learning}\\ 
\vspace{5mm}
\huge Programming Assignemnt 3\\
\vspace{5mm}
lab Report\\
\vspace{20mm}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{IIT_Madras_Logo}
\end{figure}
}
\author{}
\date{}

\begin{document}
\maketitle % Page 1
\vfill
\begin{center}
    \huge Name - Jay Jitendra Prajapati\\
    \vspace{5mm}
    Roll number - ME21B143
\end{center}
\newpage % Page 2
% Customizing the table of contents
\renewcommand{\cftsecfont}{\bfseries\large} % section font
\renewcommand{\cftsubsecfont}{\large} % subsection font
\renewcommand{\cftsecpagefont}{\bfseries\large} % section page font
\renewcommand{\cftsubsecpagefont}{\large} % subsection page font
\renewcommand{\cftsecdotsep}{\cftdotsep} % dot separation
\setlength{\cftbeforesecskip}{10pt} % space before sections
\setlength{\cftbeforesubsecskip}{8pt} % space before subsections
\setlength{\cftsecindent}{0pt} % no indentation for sections
\setlength{\cftsubsecindent}{20pt} % indentation for subsections
\tableofcontents
\newpage
\section{\ulsection{Aim}}
\begin{itemize}
    \item \large The objective of this assignment is to develop a spam classifier using labeled training data.
\end{itemize}
\section{\ulsection{About the Dataset}}
\begin{itemize}
    \item \large The Enron Dataset has been utilized for this study, consisting of a substantial volume of emails. However, a subset comprising 2000 spam emails and 2000 ham (non-spam) emails was selected for the purpose of training. It is noteworthy that the Enron dataset lacks emails pertinent to the Indian context, prompting the addition of supplementary emails. For validation, an additional set of 200 spam emails and 200 ham/non-spam emails were sourced from the same dataset.
    \item For the access to the finalized dataset, please refer to the following link: \href{https://drive.google.com/file/d/1gFdN-k4Zq8uwX22M04oO_HINlzmC1L2E/view?usp=sharing}{\textcolor{blue}{Final Dataset Dwonload}} 
\end{itemize}
\section{\ulsection{Feature Extraction}}
\begin{itemize}
    \item \large The frequency of each word in the training set is used as our feature. In the dataset, numerous words irrelevant to classification, commonly referred to as stop words, were identified and subsequently eliminated in the following procedure 
    \item \hfuzz=12pt \large A dictionary encompassing all possible words occurring across the dataset was created, along with the respective frequency counts for each word.
    \item \large A graphical representation depicting the word index versus frequency was generated. Subsequently, words exceeding a predefined threshold (3000 in our instance) were filtered out.
    \begin{figure}[ht]
        \centering
        \hfuzz=15pt \includegraphics[width=1.0\textwidth]{word_index_vs_freq}
        \caption{\large Schematic representation of word frequency versus count}
        \label{fig:mesh2}
    \end{figure}
    \item \large Upon analysis of the frequency distribution of words within the dataset, it was observed that words exceeding a frequency threshold of 3000 were deemed irrelevant for classification purposes. 
    \item \large Consequently, a rigorous filtration process was undertaken to remove such words from the emails within the dataset. This strategic curation ensures the elimination of potentially confounding variables, thereby enhancing the efficacy of subsequent analyses and classification algorithms.
\end{itemize}
\newpage
\section{\ulsection{Architecture of the classifier}}
\begin{figure}[ht]
    \centering
    \hfuzz=15pt \includegraphics[width=1.0\textwidth]{Folder_structure}
    \caption{\large structure of the folder}
    \label{fig:mesh3}
\end{figure}
\begin{itemize}
    \item \hfuzz=10pt \large Figure \ref{fig:mesh3} illustrates the hierarchical arrangement of folders within the dataset. The program selectively retrieves training data from folders denoted in blue, where the folder designation determines the label assigned to the data. Conversely, the \textbf{'test'} folder, highlighted in pink, comprises emails designated for classification using the developed classifier algorithm.
    \item The following figure \ref{fig:mesh4} depicts the overarching procedure employed in training our classifier. The \textbf{'Train.py'} script is utilized to process both training and validation data, employing cross-validation techniques to yield the optimal classifier. Subsequently, the trained model and count vectorizer objects are saved as '.object' files within the same directory for utilization in classification tasks.
    \item The \textbf{'Classify.py'} script accepts input in the form of model and count vectorizer objects, alongside test data, and generates the desired accuracy metrics based on the evaluation of the test dataset.
\end{itemize}
\begin{figure}[ht]
    \centering
    \hfuzz=15pt \includegraphics[width=1.0\textwidth]{Train_Test_pipeline}
    \caption{\large structure of the folder}
    \label{fig:mesh4}
\end{figure}
\section{\ulsection{Algorithm}}

\begin{itemize}
    \item \large \textbf{Naive Bayes Algorithm:}
    \begin{itemize}
        \item \textbf{Description:} Naive Bayes algorithm is straightforward to implement. However, it relies on the class conditional independence assumption, which may not hold true in real-world scenarios, leading to loss of data and reduced effectiveness and hence not used.
    \end{itemize}
    
    \item \large \textbf{Support Vector Machine (SVM):}
    \begin{itemize}
        \item \textbf{Description:} SVM is the chosen model for its speed and accuracy compared to Naive Bayes. It utilizes word frequencies for training. The implementation involves the following steps:
        \begin{enumerate}
            \item \textbf{\underline{Step 1:}} Load the dataset from the training and validation folders using the \texttt{load\_data} function. Convert emails to lowercase and remove stop words.
            
            \hfuzz=15pt \item \textbf{\underline{Step 2:}} Extract features using the \texttt{CountVectorizer} function from the \texttt{sklearn} library.
            
            \item \textbf{\underline{Step 3:}} Train the model using different kernels. Initially, employ a linear kernel and evaluate accuracy on the validation dataset. Then, utilize an RBF kernel with varying values of \( C \). If accuracy improves, store this model along with the extracted features.
            
            \hfuzz=150pt \item \textbf{\underline{Step 4:}} After trying all kernels, select the best model and extracted features, saving them as \texttt{model.object} and \texttt{count\_vectorizer.object}, respectively, representing the final classifier.
        \end{enumerate}
    \end{itemize}
    \item \large \textbf{Procedure for Test Email Classification:}
    \begin{enumerate}
        \hfuzz=19pt \item \textbf{\underline{Step 1:}} Load the test dataset from the designated folder using the \texttt{Load\_data} function. This function converts emails to lowercase and returns them as a list.
        
        \item \textbf{\underline{Step 2:}} Retrieve the SVM model stored in \texttt{model.object} along with the associated feature extraction parameters stored in \texttt{count\_vectorizer.object}. Employ the \texttt{CountVectorizer} to extract features from the test emails.
        
        \item \textbf{\underline{Step 3:}} Utilize the SVM model to classify the test emails based on the extracted features.
        
        \item \textbf{\underline{Step 4:}} Record the predicted classifications into the file named \texttt{'output.txt'} for further analysis.
    \end{enumerate}
\end{itemize}
\hfuzz=19pt \section{\ulsection{Hyper-Paramter Tuning and Cross validation}}
\begin{itemize}
    \item \large For the purpose of cross-validation, the validation dataset comprises 200 spam and 200 ham emails. These emails, randomly selected from the larger dataset, offer valuable insights into the performance of the classification algorithm.
    \item \large The following kernels have been selected for evaluation:
    \begin{enumerate}
        \item \textbf{Linear kernel}
        \item \textbf{Radial Basis Function kernel}
        \item \textbf{Polynomial kernel}
    \end{enumerate}
    \item \large In the RBF kernel, the 'C' hyperparameter is fine-tuned by cross-validating the Support Vector Machine (SVM) model using the validation dataset. Subsequently, the model demonstrating the highest accuracy on the validation set is chosen for further analysis.
\end{itemize}
\section{\ulsection{Cross validation Results}}
\begin{itemize}
    \item \large The table below presents the results obtained after cross-validating various SVM models using the validation dataset.
    \begin{table}[ht]
        \centering
        \begin{tabular}{|c|c|}
            \hline
            \rowcolor{blue!20} % Color for header row
            \textbf{Kernels used} & \textbf{Accuracy Percentage} \\
            \hline
            Linear kernel & 95.26184538653366 \\
            \hline
            RBF kernel with C=1 & 95.51122194513717 \\
            \hline
            \textbf{RBF kernel with C=2} &\textbf{96.75810473815461}\\
            \hline
            RBF kernel with C=3&96.25935162094763\\
            \hline
            Polynomial kernel with degree=2&76.05985037406484 \\
            \hline
            Polynomial kernel with degree=3 &61.59600997506235\\
            \hline
            Polynomial kernel with degree=4&57.10723192019949\\
            \hline
        \end{tabular}
        \caption{\large Cross Validation results on various kernels}
        \label{tab:colored_table_lines}
    \end{table}\\
    \newline
    \newline
    \textbf{Conclusion}: Upon evaluation, the \textbf{RBF kernel} with a regularization parameter of \textbf{C=2} emerges as the most effective classifier, yielding the highest accuracy among all evaluated models. Therefore, it is selected as the optimal classifier for the task at hand
\end{itemize}
\section{\ulsection{Results}}
\begin{itemize}
    \hfuzz=100pt \item \large To commence the classification process, execute the '\textbf{Classify.py}' file. Ensure that the '\textbf{model.object}' and '\textbf{count \textunderscore vectorizer.object}' files are copied from the zip archive to the same directory as the code file prior to execution. The output will be saved to a file named '\textbf{output.txt}' and displayed on the console.
\end{itemize}
\end{document}